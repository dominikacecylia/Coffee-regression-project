{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python391jvsc74a57bd0f8b6ea6d13f5748502004c2e5659a6272de46c202ad482ac9f90784c65a6c667",
   "display_name": "Python 3.9.1 64-bit (conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## Train-val-test split\n",
    "Split data into respective sets"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                         brewing_method   roast  pure_arabica  grind  \\\n",
       "0    drip (alternative brewing methods)   light          True  beans   \n",
       "1    drip (alternative brewing methods)  medium          True  beans   \n",
       "2    drip (alternative brewing methods)   light          True  beans   \n",
       "3    drip (alternative brewing methods)   light          True  beans   \n",
       "4    drip (alternative brewing methods)    dark          True  beans   \n",
       "..                                  ...     ...           ...    ...   \n",
       "857  drip (alternative brewing methods)   light          True  beans   \n",
       "858                            espresso   light         False  beans   \n",
       "859  drip (alternative brewing methods)   light          True  beans   \n",
       "860  drip (alternative brewing methods)   light          True  beans   \n",
       "861  drip (alternative brewing methods)   light          True  beans   \n",
       "\n",
       "     Fermented_closedtank  price_per_kg  \n",
       "0                   False         52.22  \n",
       "1                   False         31.92  \n",
       "2                   False         39.20  \n",
       "3                   False         39.20  \n",
       "4                   False         35.20  \n",
       "..                    ...           ...  \n",
       "857                 False         73.33  \n",
       "858                 False         50.00  \n",
       "859                 False         36.00  \n",
       "860                 False         25.00  \n",
       "861                 False         29.60  \n",
       "\n",
       "[837 rows x 6 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>brewing_method</th>\n      <th>roast</th>\n      <th>pure_arabica</th>\n      <th>grind</th>\n      <th>Fermented_closedtank</th>\n      <th>price_per_kg</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>drip (alternative brewing methods)</td>\n      <td>light</td>\n      <td>True</td>\n      <td>beans</td>\n      <td>False</td>\n      <td>52.22</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>drip (alternative brewing methods)</td>\n      <td>medium</td>\n      <td>True</td>\n      <td>beans</td>\n      <td>False</td>\n      <td>31.92</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>drip (alternative brewing methods)</td>\n      <td>light</td>\n      <td>True</td>\n      <td>beans</td>\n      <td>False</td>\n      <td>39.20</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>drip (alternative brewing methods)</td>\n      <td>light</td>\n      <td>True</td>\n      <td>beans</td>\n      <td>False</td>\n      <td>39.20</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>drip (alternative brewing methods)</td>\n      <td>dark</td>\n      <td>True</td>\n      <td>beans</td>\n      <td>False</td>\n      <td>35.20</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>857</th>\n      <td>drip (alternative brewing methods)</td>\n      <td>light</td>\n      <td>True</td>\n      <td>beans</td>\n      <td>False</td>\n      <td>73.33</td>\n    </tr>\n    <tr>\n      <th>858</th>\n      <td>espresso</td>\n      <td>light</td>\n      <td>False</td>\n      <td>beans</td>\n      <td>False</td>\n      <td>50.00</td>\n    </tr>\n    <tr>\n      <th>859</th>\n      <td>drip (alternative brewing methods)</td>\n      <td>light</td>\n      <td>True</td>\n      <td>beans</td>\n      <td>False</td>\n      <td>36.00</td>\n    </tr>\n    <tr>\n      <th>860</th>\n      <td>drip (alternative brewing methods)</td>\n      <td>light</td>\n      <td>True</td>\n      <td>beans</td>\n      <td>False</td>\n      <td>25.00</td>\n    </tr>\n    <tr>\n      <th>861</th>\n      <td>drip (alternative brewing methods)</td>\n      <td>light</td>\n      <td>True</td>\n      <td>beans</td>\n      <td>False</td>\n      <td>29.60</td>\n    </tr>\n  </tbody>\n</table>\n<p>837 rows Ã— 6 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 94
    }
   ],
   "source": [
    "coffee_df = pd.read_csv('data\\coffee_desk_dataset_final.csv', index_col=0)\n",
    "coffee_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df = coffee_df.drop('price_per_kg', axis=1) # defining predictors\n",
    "y_df = coffee_df['price_per_kg'] # defining target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_df, y_df, test_size=0.2, random_state=True) #using random state to ensure I always have random division with the same random numbers\n",
    "X_validation, X_test, y_validation, y_test = train_test_split(X_train, y_train, test_size=0.5, random_state=True)\n"
   ]
  },
  {
   "source": [
    "## Encode data\n",
    "Convert categorical data into binary vectors"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "OneHotEncoder(handle_unknown='ignore')"
      ]
     },
     "metadata": {},
     "execution_count": 99
    }
   ],
   "source": [
    "encoder = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "encoder.fit(X_train) # all variables are categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = encoder.transform(X_train)\n",
    "X_validation = encoder.transform(X_validation)\n",
    "X_test = encoder.transform(X_test)"
   ]
  },
  {
   "source": [
    "# Regression Models\n",
    "\n",
    "1. Train Models - 3 linear models wer chosen to compare their performance on data\n",
    "2. Evaluate Models using mean squared error, mean absolut error and r squared"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge, SGDRegressor\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_predictions(y_pred, y_true):\n",
    "    samples = len(y_pred)\n",
    "    plt.figure()\n",
    "    plt.scatter(np.arange(samples), y_pred, c='r', label='predictions')\n",
    "    plt.scatter(np.arange(samples), y_true, c='b', label='true labels', marker='x')\n",
    "    plt.legend()\n",
    "    plt.xlabel('Sample numbers')\n",
    "    plt.ylabel('Values')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "LinearRegression:\n\t\tMean squared error: Train: 142.8284262491378, Validation 138.10495173907364 , Test 147.53780083529136\n\t\tMean absolute error: Train: 8.50468229067323, Validation 8.177647704121394 , Test 8.830740654578648\n\t\tR squared: Train: 0.46119605105521433, Validation 0.4594200618868819 , Test 0.4622123330228176\n\tModel's bias: 36.71524149029261\nRidge:\n\t\tMean squared error: Train: 142.83692996559319, Validation 138.0639868273577 , Test 147.59562551237127\n\t\tMean absolute error: Train: 8.50628993093821, Validation 8.178257341961725 , Test 8.83334331815656\n\t\tR squared: Train: 0.46116397175470536, Validation 0.4595804095729087 , Test 0.46200155722160297\n\tModel's bias: 36.65233088284985\nSGDRegressor:\n\t\tMean squared error: Train: 143.46961798847664, Validation 138.89989879190293 , Test 148.02569623222476\n\t\tMean absolute error: Train: 8.513596507596148, Validation 8.21031272698964 , Test 8.815974963484427\n\t\tR squared: Train: 0.4587772283442232, Validation 0.4563084252423568 , Test 0.46043391335165396\n\tModel's bias: [0.1629709]\n"
     ]
    }
   ],
   "source": [
    "models = [LinearRegression(), Ridge(), SGDRegressor()]\n",
    "\n",
    "for model in models:\n",
    "    # Train each of the models\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # make predictions\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_validation_pred = model.predict(X_validation)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    # EVALUATION:\n",
    "\n",
    "    #Train Loss\n",
    "    train_mse = metrics.mean_squared_error(y_train, y_train_pred)\n",
    "    train_mae = metrics.mean_absolute_error(y_train, y_train_pred)\n",
    "    train_r2 = metrics.r2_score(y_train, y_train_pred)\n",
    "\n",
    "    # Validation Loss\n",
    "    validation_mse = metrics.mean_squared_error(y_validation, y_validation_pred)\n",
    "    validation_mae = metrics.mean_absolute_error(y_validation, y_validation_pred)\n",
    "    validation_r2 = metrics.r2_score(y_validation, y_validation_pred)\n",
    "\n",
    "    # Test Loss\n",
    "    test_mse = metrics.mean_squared_error(y_test, y_test_pred)\n",
    "    test_mae = metrics.mean_absolute_error(y_test, y_test_pred)\n",
    "    test_r2 = metrics.r2_score(y_test, y_test_pred)\n",
    "\n",
    "\n",
    "    # plot_predictions(y_validation_pred[:10], y_validation[:10])\n",
    "\n",
    "    print(\n",
    "        f\"{model.__class__.__name__}:\\n\"\n",
    "        f\"\\t\\tMean squared error: Train: {train_mse}, Validation {validation_mse} , Test {test_mse}\\n\"\n",
    "        f\"\\t\\tMean absolute error: Train: {train_mae}, Validation {validation_mae} , Test {test_mae}\\n\"\n",
    "        f\"\\t\\tR squared: Train: {train_r2}, Validation {validation_r2} , Test {test_r2}\\n\"\n",
    "        f\"\\tModel's bias: {model.intercept_}\"\n",
    "    )"
   ]
  },
  {
   "source": [
    "## Adding polynomial features to dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "def polynomial_datasets(degree: int, *datasets):\n",
    "    polynomial = preprocessing.PolynomialFeatures(degree=degree)\n",
    "    return [polynomial.fit_transform(dataset) for dataset in datasets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(669, 91)"
      ]
     },
     "metadata": {},
     "execution_count": 110
    }
   ],
   "source": [
    "X_train_poly, X_validation_poly, X_test_poly = polynomial_datasets(2, X_train, X_validation, X_test)\n",
    "X_train_poly.shape # we can see how features inclreased from 5 to 91"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "LinearRegression:\n\t\tMean squared error: Train: 122.52588745815115, Validation 118.53740394015227 , Test 126.50246505520077\n\t\tMean absolute error: Train: 7.874504095873349, Validation 7.6655383512565 , Test 8.08284606214806\n\t\tR squared: Train: 0.5377850632110095, Validation 0.5360127086020513 , Test 0.5388878974490876\n\tModel's bias: 31.030862550233625\nRidge:\n\t\tMean squared error: Train: 122.76575621158102, Validation 119.00183708536403 , Test 126.51843975831676\n\t\tMean absolute error: Train: 7.912742182759642, Validation 7.719744739385063 , Test 8.105163514362955\n\t\tR squared: Train: 0.5368801856948837, Validation 0.5341947923163949 , Test 0.5388296683154639\n\tModel's bias: 31.976091674607847\nSGDRegressor:\n\t\tMean squared error: Train: 126.12628519105185, Validation 122.81628920248984 , Test 129.4264005945734\n\t\tMean absolute error: Train: 8.132962235358724, Validation 7.9778516790296825 , Test 8.28760977510171\n\t\tR squared: Train: 0.5242029733763505, Validation 0.5192640004552374 , Test 0.5282299070004816\n\tModel's bias: [0.04645064]\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    # Train each of the models\n",
    "    model.fit(X_train_poly, y_train)\n",
    "\n",
    "    # make predictions\n",
    "    y_train_pred = model.predict(X_train_poly)\n",
    "    y_validation_pred = model.predict(X_validation_poly)\n",
    "    y_test_pred = model.predict(X_test_poly)\n",
    "\n",
    "    # EVALUATION:\n",
    "\n",
    "    #Train Loss\n",
    "    train_mse = metrics.mean_squared_error(y_train, y_train_pred)\n",
    "    train_mae = metrics.mean_absolute_error(y_train, y_train_pred)\n",
    "    train_r2 = metrics.r2_score(y_train, y_train_pred)\n",
    "\n",
    "    # Validation Loss\n",
    "    validation_mse = metrics.mean_squared_error(y_validation, y_validation_pred)\n",
    "    validation_mae = metrics.mean_absolute_error(y_validation, y_validation_pred)\n",
    "    validation_r2 = metrics.r2_score(y_validation, y_validation_pred)\n",
    "\n",
    "    # Test Loss\n",
    "    test_mse = metrics.mean_squared_error(y_test, y_test_pred)\n",
    "    test_mae = metrics.mean_absolute_error(y_test, y_test_pred)\n",
    "    test_r2 = metrics.r2_score(y_test, y_test_pred)\n",
    "\n",
    "    # plot_predictions(y_validation_pred[:10], y_validation[:10]) #plot only up to 10 data points \n",
    "\n",
    "    print(\n",
    "        f\"{model.__class__.__name__}:\\n\"\n",
    "        f\"\\t\\tMean squared error: Train: {train_mse}, Validation {validation_mse} , Test {test_mse}\\n\"\n",
    "        f\"\\t\\tMean absolute error: Train: {train_mae}, Validation {validation_mae} , Test {test_mae}\\n\"\n",
    "        f\"\\t\\tR squared: Train: {train_r2}, Validation {validation_r2} , Test {test_r2}\\n\"\n",
    "        f\"\\tModel's bias: {model.intercept_}\"\n",
    "    )"
   ]
  },
  {
   "source": [
    "** Observations: ** The R^2 has visibly increased with the use of polynomial features of 2nd degree, nevertheless, all thre models yield similar results.\n",
    "Moreover, model's bias has decreased."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Cross Validation\n",
    "Using sklearn cross_validation_score with 5 splits, to ensure results are not influenced by the initial split of data."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_validation, X_test, y_train_validation, y_test = train_test_split(X_df, y_df, test_size=0.1, random_state=True) # using random state to ensure I always have random division with the same random numbers\r\n",
    "X_train_validation = encoder.transform(X_train_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(753, 91)"
      ]
     },
     "metadata": {},
     "execution_count": 88
    }
   ],
   "source": [
    "# adding polynomial features to data\r\n",
    "polynomial = preprocessing.PolynomialFeatures(degree=2)\r\n",
    "X_train_validation_poly = polynomial.fit_transform(X_train_validation)\r\n",
    "X_train_validation_poly.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "LinearRegression:  [0.3449723  0.49843856 0.42078476 0.43668589 0.4888519 ] model's bias: 31.030862550233625\nRidge:  [0.34671939 0.49765014 0.42090051 0.43616885 0.48906956] model's bias: 31.976091674607847\nSGDRegressor:  [0.35298728 0.48676187 0.41771225 0.43456289 0.49024491] model's bias: [0.04613564]\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    scores_r2 = cross_val_score(model, X_train_validation, y_train_validation, scoring='r2', cv=5)\n",
    "    print(\n",
    "        f\"{model.__class__.__name__}: \",\n",
    "        scores_r2,\n",
    "        f\"model's bias: {model.intercept_}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "LinearRegression:  [0.44262793 0.52748237 0.4797011  0.48500845 0.54020545] model's bias: 31.030862550233625\nRidge:  [0.44184882 0.53391246 0.48057261 0.47823286 0.53987915] model's bias: 31.976091674607847\nSGDRegressor:  [0.42212874 0.53788876 0.47374473 0.46660963 0.5316073 ] model's bias: [0.04613564]\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    scores_r2 = cross_val_score(model, X_train_validation_poly, y_train_validation, scoring='r2', cv=5)\n",
    "    print(\n",
    "        f\"{model.__class__.__name__}: \",\n",
    "        scores_r2,\n",
    "        f\"model's bias: {model.intercept_}\"\n",
    "    )"
   ]
  },
  {
   "source": [
    "**Observations:** in the cross validation results are almost on the same level except of one of the folds, this can prove the model is not biased by the split."
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}