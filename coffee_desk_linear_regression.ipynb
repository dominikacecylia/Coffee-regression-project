{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python391jvsc74a57bd0f8b6ea6d13f5748502004c2e5659a6272de46c202ad482ac9f90784c65a6c667",
   "display_name": "Python 3.9.1 64-bit (conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## Train-val-test split"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                         brewing_method   roast  pure_arabica  grind  \\\n",
       "0    drip (alternative brewing methods)   light          True  beans   \n",
       "1    drip (alternative brewing methods)  medium          True  beans   \n",
       "2    drip (alternative brewing methods)   light          True  beans   \n",
       "3    drip (alternative brewing methods)   light          True  beans   \n",
       "4    drip (alternative brewing methods)    dark          True  beans   \n",
       "..                                  ...     ...           ...    ...   \n",
       "857  drip (alternative brewing methods)   light          True  beans   \n",
       "858                            espresso   light         False  beans   \n",
       "859  drip (alternative brewing methods)   light          True  beans   \n",
       "860  drip (alternative brewing methods)   light          True  beans   \n",
       "861  drip (alternative brewing methods)   light          True  beans   \n",
       "\n",
       "     Fermented_closedtank  price_per_kg  \n",
       "0                   False         52.22  \n",
       "1                   False         31.92  \n",
       "2                   False         39.20  \n",
       "3                   False         39.20  \n",
       "4                   False         35.20  \n",
       "..                    ...           ...  \n",
       "857                 False         73.33  \n",
       "858                 False         50.00  \n",
       "859                 False         36.00  \n",
       "860                 False         25.00  \n",
       "861                 False         29.60  \n",
       "\n",
       "[837 rows x 6 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>brewing_method</th>\n      <th>roast</th>\n      <th>pure_arabica</th>\n      <th>grind</th>\n      <th>Fermented_closedtank</th>\n      <th>price_per_kg</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>drip (alternative brewing methods)</td>\n      <td>light</td>\n      <td>True</td>\n      <td>beans</td>\n      <td>False</td>\n      <td>52.22</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>drip (alternative brewing methods)</td>\n      <td>medium</td>\n      <td>True</td>\n      <td>beans</td>\n      <td>False</td>\n      <td>31.92</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>drip (alternative brewing methods)</td>\n      <td>light</td>\n      <td>True</td>\n      <td>beans</td>\n      <td>False</td>\n      <td>39.20</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>drip (alternative brewing methods)</td>\n      <td>light</td>\n      <td>True</td>\n      <td>beans</td>\n      <td>False</td>\n      <td>39.20</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>drip (alternative brewing methods)</td>\n      <td>dark</td>\n      <td>True</td>\n      <td>beans</td>\n      <td>False</td>\n      <td>35.20</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>857</th>\n      <td>drip (alternative brewing methods)</td>\n      <td>light</td>\n      <td>True</td>\n      <td>beans</td>\n      <td>False</td>\n      <td>73.33</td>\n    </tr>\n    <tr>\n      <th>858</th>\n      <td>espresso</td>\n      <td>light</td>\n      <td>False</td>\n      <td>beans</td>\n      <td>False</td>\n      <td>50.00</td>\n    </tr>\n    <tr>\n      <th>859</th>\n      <td>drip (alternative brewing methods)</td>\n      <td>light</td>\n      <td>True</td>\n      <td>beans</td>\n      <td>False</td>\n      <td>36.00</td>\n    </tr>\n    <tr>\n      <th>860</th>\n      <td>drip (alternative brewing methods)</td>\n      <td>light</td>\n      <td>True</td>\n      <td>beans</td>\n      <td>False</td>\n      <td>25.00</td>\n    </tr>\n    <tr>\n      <th>861</th>\n      <td>drip (alternative brewing methods)</td>\n      <td>light</td>\n      <td>True</td>\n      <td>beans</td>\n      <td>False</td>\n      <td>29.60</td>\n    </tr>\n  </tbody>\n</table>\n<p>837 rows Ã— 6 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "coffee_df = pd.read_csv('data\\coffee_desk_dataset_final.csv', index_col=0)\n",
    "coffee_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df = coffee_df.drop('price_per_kg', axis=1) #defining predictors\n",
    "y_df = coffee_df['price_per_kg'] #defining target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_df, y_df, test_size=0.1, random_state=True) #using random state to ensure I always have random division with the same random numbers\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=0.1, random_state=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(677, 5)\n(84, 5)\n(76, 5)\n(677,)\n(84,)\n(76,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(X_validation.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "print(y_validation.shape)"
   ]
  },
  {
   "source": [
    "## Encode data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "OneHotEncoder(handle_unknown='ignore')"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "encoder = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "encoder.fit(X_train) # all variables are categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = encoder.transform(X_train)\n",
    "X_validation = encoder.transform(X_validation)\n",
    "X_test = encoder.transform(X_test)"
   ]
  },
  {
   "source": [
    "# Regression Models"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge, SGDRegressor\n",
    "from sklearn import metrics\n",
    "\n",
    "LR_model = LinearRegression().fit(X_train, y_train)\n",
    "L2_model = Ridge().fit(X_train, y_train)\n",
    "SGD_model = SGDRegressor().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_loss(model, X, y):\n",
    "    return metrics.mean_squared_error(y, model.predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training loss: 149.88620582744136\nValidation loss: 116.3509686375882\nTest loss: 90.94224112878398\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training loss: {calculate_loss(LR_model, X_train, y_train)}\")\n",
    "print(f\"Validation loss: {calculate_loss(LR_model, X_validation, y_validation)}\")\n",
    "print(f\"Test loss: {calculate_loss(LR_model, X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training loss: 149.89167872538317\nValidation loss: 116.20073507953329\nTest loss: 90.95058568716465\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training loss: {calculate_loss(L2_model, X_train, y_train)}\")\n",
    "print(f\"Validation loss: {calculate_loss(L2_model, X_validation, y_validation)}\")\n",
    "print(f\"Test loss: {calculate_loss(L2_model, X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training loss: 150.38050968099427\nValidation loss: 113.82347965163098\nTest loss: 90.05910398187402\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training loss: {calculate_loss(SGD_model, X_train, y_train)}\")\n",
    "print(f\"Validation loss: {calculate_loss(SGD_model, X_validation, y_validation)}\")\n",
    "print(f\"Test loss: {calculate_loss(SGD_model, X_test, y_test)}\")"
   ]
  }
 ]
}